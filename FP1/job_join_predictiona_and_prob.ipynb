{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix  # For evaluating model performance\n",
    "import seaborn as sns  # For data visualization\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split  # For splitting data into training and testing sets\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder  # For encoding categorical variables\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression  # For logistic regression\n",
    "from sklearn.tree import DecisionTreeClassifier  # For decision tree classification\n",
    "from sklearn.ensemble import RandomForestClassifier  # For random forest classification\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_p_df = pd.read_csv('User_profile_data_updated_Previous_job.csv')\n",
    "user_p_df.drop(columns=['Comments'], inplace=True, axis=1)\n",
    "user_p_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = pd.read_csv('User_profile_data_dummy_values.csv')\n",
    "df_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_p_df.columns = ['Clean_Current Role', 'Clean_About me', 'Clean_Education',\n",
    "       'Clean_Years', 'Clean_Skills', 'Clean_Experience', 'TEXT',\n",
    "       'Notice Period', 'Expected CTC', 'Offered Location', 'Offered Salary',\n",
    "       'Current Salary', 'Current Location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_p_df['Name'] = df_name['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_p_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_p_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_salary(string):\n",
    "    if not isinstance(string, str):\n",
    "        return string\n",
    "    res = []\n",
    "    ranges = string.split(' - ')\n",
    "    ranges = [val.replace(',','').replace('â‚¹','') for val in ranges]\n",
    "    regex = re.compile(r'\\d+')\n",
    "    for rng in ranges:\n",
    "        matches = regex.findall(rng)\n",
    "        for m in matches:\n",
    "            val = float(m)            \n",
    "            if val < 100.0:\n",
    "                val = val*100000\n",
    "            res.append(val)\n",
    "    return np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_p_df['Current Salary'] = user_p_df['Current Salary'].apply(extract_salary)\n",
    "user_p_df['Current Salary'].fillna(np.mean(user_p_df['Current Salary']), inplace = True)\n",
    "\n",
    "user_p_df['Offered Salary'] = user_p_df['Offered Salary'].apply(extract_salary)\n",
    "user_p_df['Offered Salary'].fillna(np.mean(user_p_df['Offered Salary']), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label(row):\n",
    "    notice_period = row['Notice Period']\n",
    "    offered_salary = row['Offered Salary']\n",
    "    offered_location = row['Offered Location']\n",
    "    current_salary = row['Current Salary']\n",
    "    current_location = row['Current Location']\n",
    "    \n",
    "    # We might consider these factors:\n",
    "    # A) A significant salary raise is a strong motivation to change jobs, even if the notice period is long.\n",
    "    # B) If the offered location is the same as the current location, it's more likely the person will accept.\n",
    "    # C) Even if the offered location is different, if the salary raise is significant, the person might still accept.\n",
    "    \n",
    "    salary_raise = offered_salary - current_salary\n",
    "    same_location = offered_location == current_location\n",
    "    \n",
    "    # Logic to generate labels:\n",
    "    # If the salary raise is more than 20% of the current salary, and the notice period is less than or equal to 60 days, or the location is the same, we consider it likely that the person will join.\n",
    "    if (salary_raise >= 0.2 * current_salary and notice_period <= 60) or same_location:\n",
    "        label = 1  # Joined\n",
    "    else:\n",
    "        label = 0  # Not joined\n",
    "    \n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_p_df['label'] = user_p_df.apply(create_label, axis=1)\n",
    "user_p_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_p_df['Current Location'] = user_p_df['Current Location'].fillna('India').apply(lambda x: 'Noida' if x.strip() == 'Nodia' else x.strip())\n",
    "user_p_df['Offered Location'] = user_p_df['Offered Location'].fillna('India').apply(lambda x: 'Noida' if x.strip() == 'Nodia' else x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_p_df.to_csv('Employee_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_p_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_p_df['Offered Location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_p_df['Current Location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(pd.concat([user_p_df['Current Location'], user_p_df['Offered Location']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LabelEncoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Use the LabelEncoder object to transform the Class column of principal_components_df DataFrame\n",
    "le.fit(pd.concat([user_p_df['Current Location'], user_p_df['Offered Location']]))\n",
    "user_p_df['Current Location'] = le.transform(user_p_df['Current Location'])\n",
    "user_p_df['Offered Location'] = le.transform(user_p_df['Offered Location'])\n",
    "\n",
    "# Display the first few rows of the transformed DataFrame\n",
    "user_p_df.head()\n",
    "\n",
    "with open('models/label_encoder', 'wb') as file:\n",
    "    pickle.dump(le, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = user_p_df[['Notice Period', 'Expected CTC', 'Offered Location', 'Offered Salary',\n",
    "       'Current Salary', 'Current Location', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_data.drop('label', axis = 1)\n",
    "y = final_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Assuming you have your features 'X' and labels 'y', and that your minority class has been labelled as '1'.\n",
    "X_concat = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Separating majority and minority classes\n",
    "majority_class = X_concat[y==1]\n",
    "minority_class = X_concat[y==0]\n",
    "\n",
    "# Upsampling minority class\n",
    "minority_upsampled = resample(minority_class,\n",
    "                              replace=True, # sample with replacement\n",
    "                              n_samples=len(majority_class), # match number in majority class\n",
    "                              random_state=27) # reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "upsampled = pd.concat([majority_class, minority_upsampled])\n",
    "\n",
    "# Split your data again into X and y\n",
    "y_upsampled = upsampled[y.name]\n",
    "X_upsampled = upsampled.drop(y.name, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_upsampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets using train_test_split function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_upsampled, y_upsampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV  # For hyperparameter tuning using GridSearchCV\n",
    "\n",
    "# Logistic Regression hyperparameter tuning\n",
    "lr_params = {  # Define hyperparameters for Logistic Regression\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'saga']\n",
    "}\n",
    "\n",
    "lr_grid = GridSearchCV(LogisticRegression(max_iter=1000), lr_params, cv=5, n_jobs=-1)  # Create a GridSearchCV object for Logistic Regression\n",
    "lr_grid.fit(X_train, y_train)  # Fit the GridSearchCV object to the training data\n",
    "print(\"Best parameters for Logistic Regression:\", lr_grid.best_params_)  # Print the best hyperparameters for Logistic Regression\n",
    "print(f\"Best score for Logistic Regression: {lr_grid.best_score_:.4f}\")  # Print the best score for Logistic Regression\n",
    "\n",
    "# Decision Tree hyperparameter tuning\n",
    "dt_params = {  # Define hyperparameters for Decision Tree\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "dt_grid = GridSearchCV(DecisionTreeClassifier(), dt_params, cv=5, n_jobs=-1)  # Create a GridSearchCV object for Decision Tree\n",
    "dt_grid.fit(X_train, y_train)  # Fit the GridSearchCV object to the training data\n",
    "print(\"Best parameters for Decision Tree:\", dt_grid.best_params_)  # Print the best hyperparameters for Decision Tree\n",
    "print(f\"Best score for Decision Tree: {dt_grid.best_score_:.4f}\")  # Print the best score for Decision Tree\n",
    "\n",
    "# Random Forest hyperparameter tuning\n",
    "rf_params = {  # Define hyperparameters for Random Forest\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(), rf_params, cv=5, n_jobs=-1)  # Create a GridSearchCV object for Random Forest\n",
    "rf_grid.fit(X_train, y_train)  # Fit the GridSearchCV object to the training data\n",
    "print(\"Best parameters for Random Forest:\", rf_grid.best_params_)  # Print the best hyperparameters for Random Forest\n",
    "print(f\"Best score for Random Forest: {rf_grid.best_score_:.4f}\")  # Print the best score for Random Forest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models and save them\n",
    "models_pred = {'Logistic Regression': lr_grid.predict(X_test), 'Decision Tree': dt_grid.predict(X_test), 'Random Forest': rf_grid.predict(X_test)}\n",
    "models = {'Logistic Regression': lr_grid, 'Decision Tree': dt_grid, 'Random Forest': rf_grid}\n",
    "\n",
    "# Loop through each model and print the classification report and confusion matrix\n",
    "for name, y_pred in models_pred.items():\n",
    "    with open('models/' + name.replace(' ', '_'), 'wb') as model_file:\n",
    "        pickle.dump(models[name], model_file)\n",
    "    print(f\"{name}:\\n\")\n",
    "    print(classification_report(y_test, y_pred))  # Print the classification report\n",
    "    cm = confusion_matrix(y_test, y_pred)  # Get the confusion matrix\n",
    "    print(\"Confusion Matrix:\\n\", cm)  # Print the confusion matrix\n",
    "    \n",
    "    # Plot the confusion matrix\n",
    "    plt.figure(figsize=(10, 7))  # Set the figure size\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")  # Create a heatmap\n",
    "    plt.title(f\"{name} Confusion Matrix\")  # Set the title\n",
    "    plt.xlabel(\"Predicted\")  # Set the x-axis label\n",
    "    plt.ylabel(\"Actual\")  # Set the y-axis label\n",
    "    plt.show()  # Display the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
